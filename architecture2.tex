\chapter{Architecture 2.0}
%Lines: 
%	4061 (modules)
%+	1278 (app)
%+	389 (html)
%+	663 html
%+	163
%+ 	632
%+	85
%+	737
%+	88 html
%+ 278 config
%+	1320 (models)
%+	811(models)
%=	10505
\section{Introduction}
In this section we will look at the details of Architecture 2.0, which is an implementation of Shredhub that conforms to \textit{Reference-model 2.0}. The application is completely implemented with JavaScript, both on the back-end and the front-end. The back-end is built on a Web server that is implemented using Node Js.  Note that I could have chosen to use any Web framework for this as well and still have conformed to the principles in \textit{Reference-model 2.0}. For example Ruby on Rails, or SpringMVC. However, the reason I chose Node Js is because The programming language is JavaScript, which gives me a pure JavaScript codebase, and in effect creates a more complete and coherent codebase. This also minifies the distinction between the front-end and the back-end. Even more, the framework does not automatically create Http Sessions, which is an important architectural principle in \textit{Reference-model 2.0}  where the back-end must be completely state-less.

The persistency layer is made with two popular noSQL solutions. One is a highly efficient Key-value store that serves to authenticate Users. It is built with Redis. The other is a MongoDB database which persists the rest. 

 The front-end uses various frameworks that helps improving the JavaScript codebase. These are Backbone for code-structuring, RequireJs for AMD, and JQuery for DOM manipulation.

% In this section we will discuss the design and implementation of Architecture 2.0.
% 
% An imprint decision is when and where to put script loading tags. Loading scripts blocks the page from loading other recourses and rendering. THere are many options: (this is old though=)
%http://www.stevesouders.com/blog/2009/04/27/loading-scripts-without-blocking/. 
%
%Performance enhancement: minifying and compressing html,css and js. GZIP compresses shit by identifying similar strings. the more matching strings found, the smaller the file can be compressed to. 
% 
%	  
%		  
%Cold have chosen to fetch all the HTML at once. This can be done in two ways: Fetch each HTML template one at a time, or merge all together (can be done when deploying) and fetch the whole thing then. However, I chose to lazily fetch them and cache them in the browser (guess require does this?). 	
%		  	  
%Database:
%My first attempt:
% battle requests where battler is dbrefs
% everything in mongo
%		
%Nice rest principle:
%The "stateless" constraint in reSt means that all 
%messages must include all application state.

\section{Architectural Overview}
Architecture 2.0 is a large-scale JavaScript Web application where most of the data processing and manipulation happens in the client's browser. The application is basically a complete JavaScript application that is sent to the client in the initial visit  to www.Shredhub.com. Unlike Architecture 1.0, the application's state is maintained on the client, such that the back-end is completely unaware of any reoccurring User (session). Also, instead of the using a traditional SQL database, the back-end uses noSQL technologies for data persistence. For simplicity in this chapter, we will use the term \textit{App} to refer to the JavaScript application that runs in the client's browser, and we will use the term \textit{API} to refer to the code that runs on the back-end.

In order to achieve a flexible structuring of the app's codebase, it is built with the MV* pattern. This pattern suits the application because it separates Models from Views, and it lets Views help out with controller specific logic. I could have designed the app around a traditional MVC architecture, but I felt this approach didn't quite fit with the application's needs. The reason is that MVC is very controller-oriented and structures the application around a set of controller handlers. However, in this app, Views aren't just Html files that contains some special syntax to render the Model's data. They are JavaScript objects that listen to events that occurs in their belonging part of a page. Therefore, considering that Views are both event-aware and responsible for creating dynamic Html pages, I wanted to let the Views be the first-order citizens and have them both be responsible for communicating with the Models, and control the data flow. Also, other architectural patterns would also fit the application quite well, examples being the MVVM pattern and MVP. These however, are even more view-logic oriented, something that might fit applications that contain a lot of updates of the visible data. Something Shredhub does not have in a high degree.  

The App is bootstrapped from a single JavaScript reference in the initial Html, which simply asks the browser to fetch a particular JavaScript file that has a reference to a main function. This function loads in the rest of the necessary part of App, and from there on, everything is controlled by the App.

The app is composed of a set of loosely coupled modules, where each module contains a set of zero to many \textbf{Models}, \textbf{Collections} and \textbf{Views}. These are core entities in the application that together provides domain data, business operations, controller handling and view logic. Each module is a separate JavaScrip source file. The app uses the Asynchronous Module Definition pattern to lazily fetch scripts and define dependencies between modules. The alternative was to eagerly fetch the whole app in the initial request. However, considering this would require a large amount of JavaScript and Html files to be fetched over Http, the AMD solution was chosen as to avoid a potentially time consuming and resource demanding bootstrapping process. This way, unnecessary fetches can be avoided. Say for instance the User only accesses the Login page and Shredpool. In this case, the app will never load the Scripts and Html templates required for displaying the Shredder-, Battle-, or List of Shredders page. 

In addition to Models, Collections and Views, there are three other central components in the app: The \textbf{Router} is a module that is responsible for managing data flow between the main pages in Shredhub, where the main pages being the ones that can be accessed through a unique URL. The \textbf{Session} is a  module that offers a facade to manage session data. And lastly the \textbf{Mediator} which is a module that coordinates communication between the independent Views and Models. This facilitates a loosely coupled communication scheme inside the app, so that the communicating entities don't need to have many and complex relations to each other. 

The Models are responsible for persisting and manipulating data. This is done by communicating with the API, using Ajax. The transport format used is JSON, which is a natural choice because no marshaling needs to be done the app, considering JSON is already a JavaScript supported data format. 

The API is organized as a Rest API, meaning it publicly offers a set of services that conforms to the Http messaging scheme. In the API, the first-order citizens are the application's core resources (domains). In Architecture 2.0, these are Shreds, Shredders, Battles and BattleRequests. Hence, the API offers a set of self-contained operations that manipulates these resources. In respect to \textit{Reference-model 2.0}, the API is stateless. To achieve this, every Rest operation has to contain all the information that is needed in order to execute that operation. In other words, no API operation depends on the result, or state from another API operation. 

The API is responsible for communicating with the database. Now, because both databases are manipulated with JavaScript, no serializing of data is needed, which in effect simplifies the programming model. Figure \vref{arc2} shows an overview of the main software components in Architecture 2.0.

 \begin{figure}[h]
  \centering
  \includegraphics[scale=0.6]{images/arc2.eps}
  \caption[sp.]
   {The main software components of Architecture 2.0.}
    \label{fig:arc2}
\end{figure}



In the rest of this chapter we will go into details of the implementation of  Architecture 2.0. This chapter will be somewhat different the the previous chapter which discussed Architecture 1.0. This is because Architecture 1.0 is very much back-end oriented, and therefore focused mainly on the back-end implementation. Architecture 2.0 is rather front-end oriented, but the back-end implementation is also very unique and relevant. Therefore, the following text is divided into a front-end section and a back-end section.

\section{The Front-end}
Also referred to as the \textit{App}, the front-end is composed of a large JavaScript codebase and a set of Html template files that are used to dynamically generate Html. The codebase is divided into 6 independent components: Models, Collections, Views, Router, Mediator and Session. 

\subsection{The Bootstrapping Process}
In Architecture 2.0, a fairly large JavaScript application has to be downloaded and initialized in the client's browser during the client's initial request to the Shredhub. I call this the bootstrapping process, because the client will ask for a small Html page that contains one single line of JavaScript. This statement is responsible for starting a recursive process that loads in the rest of the App from the server. In detail, the bootstrap process works like this:

\begin{enumerate}
\item{} The client visits www.shredhub.com and the server responds with a file called index.html
\item{} index.html contains the line \\ \textit{<script data-main="/app/config" src="/vendor/js/libs/require.js"></script>}, which will fetch a JavaScript file called require.js from the server
\item{} require.js is a framework that implements the AMD specification. It will fetch a file called /app/config.js (outlined in the script statement above), which contains a reference to the \textbf{main} function.
\item{} The JavaScript file that has the main function is fetched from the server, and the main function is called
\item{} The main function is responsible for instantiating objects that will be globally accessible (that is, accessible through the whole codebase). This includes the Session, Mediator and the Router object. Also, a globally accessible object called \textit{app} is created. This object will cache Html templates in the browsers JavaScript heap memory, so that Html templates won't have to be fetched more then once. 
\item{} When the Router object is initialized it will start listening to Url changes. 
\item{} At the end of the bootstrapping process, the router will handle a request for the home page. This will result in the Home page View being created and rendered in the browser.
\end{enumerate}

\subsection{Router}
The Router is the component that organizes routing between the Shredhub's main pages. Normally, every hyperlink request or form submit would make the browser send the request directly to the server. This however, is unwanted in Architecture 2.0, because the front-end is supposed to decide when and how to contact the server. This is where the Router comes in. The router is configured to listen to every hyperlink-event or form submit that is triggered in the app, so that when such an event is triggered, the router is notified, and it will call the \textbf{event.preventDefault()} function on the browser, which in effect tells the browser not to issue the Url request to the server. This way the Router has hijacked the request, and is now able to decide what will happen.  

To some extend, the router works as a Controller from Reference-model 1.0, in that it receives a particular page request (for example www.shredhub.com/shredders), however unlike Reference-model 1.0, there is no controller handler for every possible request. There is just one handler for every possible hyper-link. Now, it so happens that I have chosen to have only 5 different hyperlink possibilities in my app, namely the ones that refers to any of the 5 pages offered in Shredhub. Hence there will be 5 controller handlers, or routes, as they are called in Architecture 2.0. After the router has hijacked a Url request from the browser, it will call the route handler for that particular Url. The handler's responsibility is very simple. It will remove the current View, and create the new View that will be displayed in the browser. The Router is implemented in a JavaScript file called router.js. It primarily contains a key-value mapping between a Urls a JavaScript function (the route handler). The url-handler mapping in router.js is showed below:

\begin{enumerate}
\item{} '*actions':	'renderHomeView' \textit{ //www.shredhub.com}
\item{} 'shredPool': 	'renderShredPoolView', \textit{//www.shredhub.com/shredpool}
\item{} 'shredder/:Id':	'renderShredderView', \textit{//www.shredhub.com/shedder/<shredderId>}
\item{} 'shredders': 	'renderShreddersView', \textit{//www.shredhub.com/shredders}
\item{} 'battles/:Id':	'renderBattleView', \textit{//www.shredhub.com/battles/<battleId>}
\item{} 'battles':	'renderBattlesView', \textit{//www.shredhub.com/battles}
\end{enumerate}

\subsection{Models}
The Models represents the domain resources of the application, which implements both business logic and data attributes. Hence they implement the Domain Model design pattern. I chose this as opposed to having a separate service layer. An additional service layer does result in more decoupling and separation of concerns (business operations and data holders in this case), but it also leads to more code and additional source code files. In this architecture, less code and files are to some extend preferable, considering these are data that must be transmitted over Http.

Models are built with the Active Record design pattern, meaning they are responsible for knowing how to perform CRUD operations on themselves. Hence, I avoid having to have additional modules that only concerns data source handling. Now, since CRUD'ing in this case means talking to the database, and the database lives on another physical machine that the the client; CRUD'ing happens via HTTP. Hence, Models will use Http to talk the the API on the server.  

Like in Architecture 1.0, the models are totally unaware of how they are visualized in the Views. I prefer this solution here as well, because it separates two very different concerns, and the Models and Views can change independently of each other. I could have chosen to let the Models have closer connections to the DOM tree, so that  whenever the Models change, they can notify the View(s) of the change, in effect making the Models View-aware. This design fits more in applications where Models changes frequently. However, in this application I have avoided letting the models change frequently on purpose, because it would require me to get frequent new information from the database, a problem discussed in the previous chapter. If I were to choose to let the Models change often however (e.g let them get automatic updates from the API when a new comment is made for a Shred), letting the Models be completely View-aware and automatically update the View on change events, would have been a reasonable solution. 

\subsection{Collections}
Considering that the application has many ``collections'' of Models, e.g a list of Shredders on the Shedders page, multiple rows of Shreds in the Shred-pool page etc, it makes sense to encapsulate these Models in separate modules (Collections). This way, a Collection is a container for multiple coherent Models. The motivation for this, is that the Collections can also work as Active Records, in that they can be responsible for fetching a particular set of Shreds or Shredders from the database, regarding the collection of Models they control. For example a Shred-Collection representing a row of top-rated Shreds, would know how to fetch the top-rated Shreds from the API. Like with Models, I have decided to let the Collections not be View-aware.

\subsection{Views}
The set of pages in Shredhub are in Architecture 2.0 separated into logical coherent Views. These Views are JavaScript objects that holds a reference to a piece of Html  which it is responsible for maintaining. A View  contains zero or more Model and Collection objects, that represents the data that is displayed in the View, and are being used to delegate business logic operations to. The view's main job is to render an Html template together with its containing set of Collections and/or Models. In addition, the View is responsible for maintaining state for the particular Html portion of a page it represents, and to handle all user-events that happens inside that Html portion. A View can contain one or more sub-views, such that Views can form a tree of Views. Views are created ether by the Router when a page is to be rendered, or by a parent View, when it needs to create a child View that will renderer a smaller part of Html inside the current View.

There is one root View called the ScaffoldingView, which is the root view that contains visual elements that are always visible in the app (top navigation bar and footer). This View wraps one single child View. This child view (called the MainContentView), is the always the View that represents the current Shredhub page. For example, when the Login page is showed, MainContentView is set to point to the LoginView, and  when the Shredpool is showed, MainContentView is set to point to the ShredpoolView etc. The set of Views in Architecture 2.0 is given in the table below:

\begin{table}[htbp]
  \centering
  \begin{tabular}{|p{4cm} | p{8cm}|}
    \toprule
    View Name & Responsibility \\ 
    \midrule
    Scaffolding View & Contains the header and footer that is contained in every page. Always wraps one sub-view \\ 
    Home View & Represents the login page. Wraps a set of sub-views; a list of ShredThumbnail Views, and a ShredModal View \\ 
    Shredpool View & Represents the Shredpool page. Wraps a set of ShredRow Views and a ShredModal View \\ 
    Shredders View & Represents the list of Shredders page \\
    Shredder View &  Represents the Shredder page\\ 
    ShredRow View & Represents a particular row of Shred thumbnails. Maintains state for the row, so that it knows how to advance to a new row the same Collection of Shreds.  Each column in a row is wrapped in a ShredThumbnail View\\ 
    ShredThumbnail View & Represents a Shred thumbnail, consisting of a thumbnail image, and metadata about the Shred. Knows how to notify a listener if the Shred was clicked, in order to tell the listener to open a ShredModal View to play the Shred itself \\ 
    ShredModalView & Represents the popup window that plays a Shred. Handles user events like rate button clicked and comment text submitted  \\ 
    \bottomrule
  \end{tabular}
  \caption{The set of Views that are implemented in Architecture 2.0}
  \label{tab:label}
\end{table}

\subsubsection{A View's Data Flow}
Views are created and removed using the Template Method design pattern. It is so that Views share a lot of common initialization code, and termination code. Therefore, I have chosen to create a super type \textit{BaseView}, that all other Views extend. This way, when a new View is created and is to render its containing Html template(s), it executes a template method defined in BaseView. The creation of a new View is described below:

\begin{lstlisting}
// The caller (Router or parent View) does:	
	1. call showView() with reference to view v and an html tag t

// In the showView function
	2. if there is a current view that is to be overridden, remove this first
	3. call v.render function
	
	8. Upon return, inject the returned Html to the DOM, inside the t tag 
	9. Call view.postRender
	
// In BaseView.render:
	4. fetch this.Html-template from server, or cache
	5. call this.serialize() to populate a data object for the template
	6. render the Html template together with the populated data
	7. return the rendered Html

// In BaseBaseView.serialize:
	5. Do nothing, expect this to be overridden
	
// In BaseView.postRender:
	10. Do nothing, expect this to be overridden

// In concrete View.serialize:
	5. populate and return a JSON object with proper Model and/or Collection data
	
// In a concrete View.postRender:
	10. Fetch any necessary Models or Collections from the API
	11. Render additional Html templates and inject these to the Dom
	12. Create event listeners and map them to event handler functions
\end{lstlisting}
Note the number 5 and 10 indicates template functions that are implemented by the current subtype of BaseView. These are custom behaviors that cannot be implemented in the BaseView. All other operations like fetching a template, and rendering it however, are common behavior, and therefore implemented in the BaseView. This neatly shows the elegancy of the Template Method pattern.

The BaseView has one other necessary feature, which is to implement a clean-up function that is called every time a View is to be removed. Views are always removed whenever a new View is to be displayed instead of it, for example  when the User goes to a new page inside the app, or clicks the next row of Shreds button. In these cases it is important to remove View's containing Html from the Dom tree, any also to remove event listeners the View created. Note that if a View contains child Views, then these Views must also be removed. Thus, the remove function in the BaseView is a recursive function that calls a clean-up method in every child View, if there are any, before it cleans up and removes itself when the recursion completes. 

It is especially important to remove any event listeners when a View is deleted. If they are not removed, they will continue to exist and listen to events, so that if a View is recreated, its old events will co-exist with the newly created event listeners. Now, when an event is triggered, there might be multiple listeners listening to that event, and in affect calls to the same handler function, so that it is executed more then once. The result could be multiple equal write operations sent to the database. Also, this could lead to slow performance, because the listeners consumes memory.

\subsubsection{Event handling}
Each View is set up to listen to certain events that are relevant to that View. For example a ShredRowView is initialized to listen to the \textit{next-row} button clicked, and a ShredModal View is initialized to listen to the \textit{rate} button. In each View, there is an \textbf{event handler} function for every event it listens to. In Architecture 2.0 I have separated the types of events into two: \textbf{View-logic event} and \textbf{Domain-logic event}. A view-logic event is something that simply manipulates the DOM tree in order to alter the Html. An example being when the User clicks the \textit{next-row} button, in which case the responsible ShredRowView will respond by advancing the set of displayed Shreds to a fresh set of Shreds. A Domain-logic event however is more like a controller handler from Architecture 1.0, where an event that requires some business operation is triggered. An example is when the rate-button is clicked in a ShredModalView. This event requires some business logic, something that should not be implemented inside the View, as it would violate the separation of concern principle. Instead, the event is delegated to a particular function in a Model object, namely the a Shred Model object that represents the Shred that is currently displayed in the View. Often, however, a domain-logic event results in something that also requires some change in the user interface. Therefore, Domain-logic events will in certain cases perform view logic. However, this is implemented inside the View object, after the Model is done with the operation.

\subsubsection{Html Templates}
Each View has one or more Html templates that they are responsible for injecting into the Dom tree. Also, the Views know where in the Dom tree to put the particular Html template. For example the ShredRowView that represents the ShredRow of top-rated Shreds holds an Html template called \textit{ShredsRow\_topRated.html}, which the View will inject into the Html tag \textit{<div id=``topShreds''></div>}. Just like JSP template files in Architecture 1.0, the templates in Architecture 2.0 are not pure Html files, but contains special syntax that can reference Model data, and supports loop statements, conditional statements and other simple programming language statements. However, there is a big difference between the way I have implemented templates in Architecture 1.0 from Architecture 2.0. In Architecture 1.0, the templates where coarse grained, and contained a lot of view-logic to decide the outcome of the Html. In Architecture 2.0, I have decided to create many, and smaller fine-grained Html templates, and factorize out as much view logic as possible into the View. This is often done by letting Views have references to multiple fine-grained Html templates. These all have the advantage of being able to be reused in other parts of the app. Also, I have implemented a couple of fine-grained Views, that are being  reused across the app. For example, a ShredThumbnailView is reused as a child View of other Views who need to display Shred thumbnails. 

Abstracting View-logic out of the Html templates and into the Views, facilitates a better decoupling of Html markup and view-logic. This decoupling was not achieved in Architecture 1.0. One example: In Architecture 1.0, the ShredderView.Jsp contained many if-checks to figure out the relationship the User had with the particular Shredder that was to be displayed. A unique Html output was to be created depending on: 
\begin{itemize}
\item{} if the visited Shredder is actually the same Shredder as the User
\item{} else if the User has sent the Shredder a battle request
\item{} else if a battle request from that Shredder is currently pending
\item{} else if they are currently in a battle
\item{} else; the User should then challenge the Shredder to a Battle
\end{itemize}
Therefore, the Jsp template had to include Html markup for every possible outcome, and depend on complex Jsp if-conditions to know which part of the Html to render (together with the rest of the Jsp page of course!). In Architecture 2.0, all of this is figured out \textbf{before} the rendering process begins. Now, the Html for displaying each of these five different shredder relationships are represented in separate (fine-grained) Html template files. This way, when the rendering process begins, the View will pick the proper Html template depending on the result of the if-check, and inject this template into the Dom. In effect, the templates contain very little view logic, only enough to display the data from a Model object it receives when the Html is rendered. This is somewhat easier to maintain in case the View becomes large and complex. 

The Html templates are cached in the browser's JavaScript heap after the first time they are fetched from the Server. One problem however, with having many small Html templates is that it results in a large number of Http request-response cycles, because each Html template is a separate Http request sent to the server. A solution to this is to bundle all the Html templates into a single file, in a build process before the application is deployed. Unfortunately, I have not had the time to implement this for the thesis. 

\subsection{The Mediator}
There are many cases in which disparate components need to communicate with each other in the app. For instance, separate Views need to communicate with each other, and sometimes Views need to communicate with Model objects they don't necessarily have direct references to. In order to facilitate a loosely coupled, flexible and efficient communication model, I have chosen to use the Mediator design pattern. This is a component where Views and Models can publish and subscribe to certain events, such that when someone publishes to the Mediator that an event has happened, the Mediator will notify every listening entity (subscriber), and call all of the handler functions the subscribers has registered with the Mediator. This solves the need to have many object references in every View and Model in order to call functions across the objects. The major events that are actively being used in the app are given below:

\begin{description}
  \item[updateNavbar] \hfill \\
  Called on the ScaffoldingView when something requires the top navigation bar to be updated. For example if the User adds a new fanee.
  
  \item[openUpShredModal] \hfill \\
 Called on the Home, or Shredpool View (depending on who's active) when a ShredThumbnailView has been clicked, and a ShredModalView (pop-up window) is to open and display a Shred video.  
 
  \item[authenticationFailed] \hfill \\
Called on the HomeView when a User fails to login. Authentication is implemented in a separate module, which uses the Mediator to route authentication results to a proper handler (here, the HomeView) that will display an authentication failed message to  the User.

  \item[authenticationSuccess] \hfill \\
 Same scenario as defined above.
 
  \item[acceptBattleRequest] \hfill \\
 Called on the Model object that implements the abstraction of a User. It will call a Rest operation on the API that creates a new battle between two Shredders.
   
  \item[addFaneeRelationship] \hfill \\
 Called on the the Model object that implements the abstraction of a User. It will register a new fanee relationship to the API.

\end{description}

\subsection{Session}
In Architecture 2.0, state is completely implemented on the client so that the server has no awareness of any logged-in User or session. In order to do this, the app needs to have a means of storing and manipulating state data on the client. This could be done by storing data in the browsers JavaScript memory, considering the single-page app scenario does not require the page to refresh. Unfortunately, this could negatively affect the browser's performance if the data size grows quite large, and also, if the User happens to manually refresh the page, the JavaScript memory is cleared. It could also be done by storing all the state inside cookies, but this is not as secure considering the state data needs to be transported in every Http request. This of course, would also waste and consume very much bandwidth. A solution is to use HTML5 WebStorage, which neither affects browser performance, or is subject to data loss on page refresh. The storage size is big enough to hold many megabytes of data (depends on the browser), so in practice there is need to limit how much User data to store in the browser. I have chosen to use session storage and not local storage, so that state data is restricted to a session. This is because the data I store in web storage is naturally bound to a ``session'', and shouldn't last for any longer then this. There is one misfortune with this design decision however; some old browsers do not implement HTML5 Web Storage. Now, I have not have the time to design a backup solution for such users, however a simple approach is to check during the bootstrap process if the current browser supports Web Storage, and if not, use the browser's JavaScript memory or cookies to store state data.

The app mostly uses sessionStorage to store User data only, considering much of the other state data is maintained in the Views (i.e JavaScript memory). The storage is populated with User data when the User is authenticated. This data includes:

\begin{itemize}
\item{} User profile data, like username, address, birthdate, list of guitars etc
\item{} Authentication details (a token made up of username and password)
\item{} List of the User's fanees
\item{} List of the User's current sent and pending battle requests 
\item{} List of the User's current battles
\end{itemize}

An API that wraps the session storage object is implemented in a separate module called Session (in session.js). This is a facade that offers handy functions like \textit{getUser()}, \textit{setUser()}, \textit{getSentBattleRequests()}, \textit{getBattles()}. Inside the facade, these functions manipulates the sessionStorage as if they were a database mapper. Considering sessionStorage only manipulates key-value pairs as text strings, the facade serializes JSON objects into a large structured string before it stores it in the sessionStorage data vault. Hence when the facade is to get data from sessionStorage, it will serialize the text string back to a JSON. 

\subsection{Summary of The Front-end}
The App goes through a bootstrapping process when the client first accesses Shredhub. This process starts from a single script loading statement in the initial html page, that leads to the loading of the rest of the JavaScript application. After the App has completely initialized itself in the browser, it will start listening to Url changes in the browser. Every Url is hijacked by the router which will create a particular view instead of letting the browser send the request to the server.

Models and Collections implement the domain of the application, and is built with the domain model pattern, and the active record pattern.

Views represent a particular part of Html, and is responsible for listening to and handle events that occur in their owning Html. Views have references to Models and/or Collections. Views can be nested in order to delegate complex and coherent View-logic into sub Views.

Independent modules communicate through a central Mediator in order to avoid complex references and to provide controlled message routing. 

The App implements the notion of a session by using the browser's sessionStorage to persist session data. Together with state data that is kept in the JavaScript Views, the App completely maintains all of the application's state.

\section{The Back-end}
\subsection{The Rest API}
The Rest API is the communication boundary between clients and the server. Models and Collections in the App communicates with the backend through the Rest API in order to perform CRUD operations on themselves, in the database. The back-end exposes all of its available operations through the Rest interface. The operations are resource-oriented, meaning they are centered around the application's domain. The domains are \textit{Shreds, Shredders, Battles} and \textit{BattleRequests}. For each domain, there are four main operations that are offered, one for each Http method: \textit{Get, Post, Put} and \textit{Delete}. Now, in order to offer more complex operations then just a combination of a resource and an Http method (e.g Get + Shred), the Rest API adds an additional verb that describes a specific operation that is to be performed. One example is \textit{Get + Shred + bestRated} which fetches the best rated Shreds on Shredhub. Given below is a list of some central operations exposed in the Rest API. These should be fairly self-explanatory:

\paragraph{Shreds}
\begin{itemize}
\item{} GET: api/shreds/NewShredsFromFanees/<uid>/?offest=<o>\&page=<p>
\item{} GET: /api/shreds/shredsByTags/?tags=<t>\&offest=<o>\&page=<p>
\item{} POST: /api/shreds 
	\begin{itemize}
	\item{} Request body: JSON \{Shred\}
	\end{itemize}
\item{} PUT: /api/shreds/<uid>
\end{itemize}

\paragraph{Battles}
\begin{itemize}
\item{}POST: /api/battles
	\begin{itemize}
	\item{} Request body: JSON \{Battle\}
	\end{itemize}
\item{}GET: /api/battles/battlesForTwo
	\begin{itemize}
	\item{} Request body: JSON \{Shredder1, Shredder2\}
	\end{itemize}
\end{itemize}

\paragraph{BattleRequests}
\begin{itemize}
\item{} DELETE: /api/battleRequests/<uid>
\item{} GET: /api/battleRequests/shredder/<uid>
\end{itemize}

\paragraph{Shredders}
\begin{itemize}
\item{} GET: /api/shredders/mightKnowShredders/<uid>/?offest=<o>\&page=<p>
\item{} GET: /api/shredders/<uid>/addFanee
	\begin{itemize}
	\item{} Request body: JSON \{Shredder\}
	\end{itemize}
\item{} GET /api/shredders/<uid>
\end{itemize}

And in addition there is one central operation:
\begin{itemize}
\item{} /api/authenticate
	\begin{itemize}
	\item{} Request body: JSON \{Base64 encoded username:password\}
	\end{itemize}
\end{itemize}

The \textit{<uid>} field is a unique identifier for the resource. In addition to the resources and verbs that define an operation, many of the API offer support for additional arguments in the query string and in the request body. Also, all of these Restful Url's must contain an authentication token that the backend uses to verify that the User is allowed to perform the operation. The App appends this token to the Http Authorization header parameter on every API request. 

It's important to notice that these URL's are all self-contained, in that they have all the information needed to perform the operation. Take for example the URL \textit{GET: api/shreds/NewShredsFromFanees/5142b8fc174328d087ac49b9/?offest=20\&page=3}. The long string represents a unique Id (uid) for a Shredder. With this request the backend will query the database for a set of Shreds that are made by the Shredder with the given uid's fanees. Also, for security reasons, the backend checks that the uid matches the User identified in the authentication token. This scenario is implemented in many of the API operations where the backend must be sure the calling User is allowed to perform a particular operation. The returned list is a set from the query result, starting at result number 3*20, and the size of the result being 20 Shreds. In a similar operation in Architecture 1.0, the back-end would look at the Http Session to find the User (i.e a Shredder) who issued the request, and by knowing what page number the User is currently at, and the amount of Shreds that are displayed on the current page, the back-end would have all necessary information to issue the request. Hence all the necessary information in that case is on the server. 

In cases where complex data structures need to be stored or updated in the database, the client sends this data as JSON objects in the Http request's response body. An example of a Shred that is saved to the database could look like this:

\begin{lstlisting}

Request URL:http://localhost:3000/api/shreds
Request Method:POST
Content-Type:application/json
Request Payload
{"description":"Sweet Shred in C-minor",
"shredRating":
{
	"numberOfRaters":0,
	"currentRating":0
},
"shredComments":[],
"owner":
{
	"_id":"5142b8fc174328d087ac49b9",
	"username":"Michael"
},
"tags": ["Scale","Speed-picking","Melodic"],
"shredType":"normal",
"timeCreated":"2013-03-18T12:24:13.363Z",
}
\end{lstlisting}

In this Rest operation, the backend responds with a status code, indicating if all went well, in addition to a JSON object, being the Shred after it is saved to the database. 

The back-end always return an Http status code which serves to inform the client if the operation was successfully executed or not. The Http status codes used are:
\begin{itemize}
\item{}200 OK, meaning the operation was performed, and the response contains JSON data
\item{} 401 Unauthorized, meaning the User is not allowed to issue this request. An example is if the User tries to add a Shred, and the owner is set to reference a Shredder who's un-equal to the Shredder identified in the authentication header.
\item{} 400 Bad Request, meaning the User tries to perform an operation with illegal input parameters. An example is if the User tries to add a rating to a Shred with a value higher then 10.
\end{itemize}
There are many other status codes supported by Http, which I could have used in order to enrich the error messages used in the application. However, this goes a bit out of scope for this thesis. The point here is to show how error handling can be done in a stateless and decoupled fashion; the back-end does not know how the App treats the error message. This is apposed to Architecture 1.0, where in cases of an error, the server will return a completely rendered error page back to the client.

\subsection{The Data Repository Layer}
The data repository layer is the part of the backend that implements the Rest API and communicates directly with the database. It is organized as a set of controller modules; one for each domain resource. This is JavaScript code that runs on a Node js server. Much like controllers in Architecture 1.0, the controllers in Architecture 2.0 are mapped to a specific (Restful) Url. However, instead of going through a complex domain logic layer, and data source layer, the controller's responsibility is much more simplified. Generally a controller handler does:
\begin{enumerate}
\item{} Validate the parameters given in the Url query string, request body and authentication header.
\item{} If there is illegal input, send a proper Http status code back to the client.
\item{} If not, create a database query with the Url arguments and execute the query on the database.
\item{} Send the result (with no modification) back to the client. 
\end{enumerate}

Notice the last statement. This is because the data format returned from the database happens to be JSON, which is the one transmission format used by the Rest API, and also the App. This point highlights an important attribute of Architecture 2.0, namely the simplicity of the backend architecture. There are other popular transmission formats that can be used as well, for example XML. However, this format is somewhat more complex, and requires marshaling considering it is not a data format supported natively in JavaScript. 

\subsection{Authentication}
Authentication in Architecture 2.0 is implemented with the Http basic authentication protocol. The App authenticates Users through the Rest API by concatenating the User's username and password into a base64 encoded string. This string is appended to the Http authentication header parameter, and is sent with every API operation (except the initial request for the home page). The reason it is sent with every request, is in respect to \textit{Reference-model 2.0}, where the server is stateless. Hence, every Url request must contain User information. Now, Http basic authentication is not a complex and especially secure protocol, so the solution is not optimal. A first improvement is to enforce the use of Https in order to properly encrypt the the username and passwords. Other authentication protocols could also have been chosen. One popular solution is OAuth, which is much used in Web 2.0 applications. However, this is a somewhat complex protocol that requires some effort to implement. This is why I decided to go for something simpler, that still conforms to a stateless solution. 

\subsection{The Databases}
There are two databases used in Architecture 2.0. The reason for this is because I have two different persistency needs. One is to persist the domain model in a flexible and efficient way, which is done with MongoDb. The other is to have authentication data available in a highly efficient manner, which is done with Redis.

\subsubsection{User Authentication with Redis}
 In Architecture 2.0, the authentication token needs to be verified in every Url request except those regarding the home page. Therefore, the back-end must have a highly efficient way to authenticate an API request. The solution I have made for this is to store authentication details in Redis. With Redis, I store two key-value pairs for each User, one that maps a username to a unique Id, and the other maps the unique Id to the password that belongs to that User. The unique Id is the same unique Id that is used for that particular user in MongoDb. An example of a User in Redis looks like this (The long string represents a unique identifier):
\begin{lstlisting}
username:Michael:uid 5142b8fc174328d087ac49b9
uid:5142b8fc174328d087ac49b9:password 1234
\end{lstlisting}
Keys are on the left-hand side of the white space, while values are on the right. The colons are used to infer a descriptive semantic. For example the key \textit{username:michael:uid} neatly describes the value \textit{unique id for an entity with username equal to ``Michael''}. A similar semantic applies to the second key-value pair. In order to authenticate a User, the backend does the following lookup:
\begin{lstlisting}

function authenticateUser(username, password) {

	// Create a string on the form ``username:<username>:uid'':
	usernameStr = ``username:'' + username + ``uid'' 
	get the value with key=usernameStr from Redis, put result in res
	
	if ( success ) {
	// A user exists with the given username. Now check the password
	 // Create a string on the form ``uid:<uid>:password''
	var uid = res.toString();
	var passwordStr = "uid:"+uid + ":password"
	get the value with key=passwordStr from Redis, put result in res
	
	if ( success ) {
	 if ( password === res.toString() ) {
	 // Correct password was given. Return success together with the uid 
	 }	
	}	
	// Authentication failed, return proper error message
} 
\end{lstlisting}
The uid is returned so that it can be used to fetch the newly authenticated Shredder from the database. 

The reason Redis was chosen is because of its extremely high speed when it comes to simple key-value pair lookups. Redis is not meant for complex and structured data, but is specialized to operate on simple HashMap data structures. Also it favors speed over durability, something that is preferable in this occasion, considering the only time I perform write operations to Redis is when new Shredders are created. If the system was to crash however, before any newly created Shredders are saved to disk, it wouldn't be that big of an issues, considering all the data except the password is already stored in MongoDb. It would just be a matter of asking the User to create a password. 

\subsubsection{MongoDb}
The domain in Architecture 2.0 is persisted using MongoDb. The reason I chose MongoDb for this, is mainly because it uses a JSON-like format to persist data, which is a very nice fit for the domain; much of the domain has a nested structure, which is very appropriate to implement with JSON. In general, this nested data structure is very typical Web 2.0 apps that has blog-posts and comments (with commenters). Also, considering the MongoDb database can be manipulated directly using JavaScript, there is no need to implement additional data mappers for creating queries and serializing query results. A final reason I chose MongoDb is because of MongoDb's schema-less document model, allows for highly flexible data modeling solution. Hence, I can very easily customize my MongoDb collections to fit the data exactly like they are displayed in the App. This does require some duplication of data, but avoids tedious relations across collections, that normally requires join operations in order to fetch the necessary data.

Examples of the set of MongoDb collections implemented i Architecture 2.0 is given below:
\paragraph{Shredder}
\begin{lstlisting}
"_id" : ObjectId("5142b8fc174328d087ac49f7"),
"username" : "Shreddaz64",
"fanees" : [
		{
			"_id" : ObjectId("5142b8fc174328d087ac49f5"),
			"username" : "Shreddaz62",
			"profileImagePath" : "EddieVanHalen.jpg"
		}
],
"birthdate" : ISODate("2013-03-15T06:00:28.202Z"),
"country" : "Denmark",
"profileImagePath" : "Hslash.jpg",
"email" : "shredder64@slash.com",
"guitars" : [
	"Gibson flying v"
],
"equiptment" : [
	"Orange"
],
"description" : "Simple test shredder #64",
"timeCreated" : ISODate("2013-03-15T06:00:28.202Z"),
"shredderLevel" : 84
\end{lstlisting}

\paragraph{Shred}
\begin{lstlisting}
"_id" : ObjectId("5142b90a174328d087ac4a2e"),
"description" : "Simple test shred #19",
"owner" : {
	"_id" : ObjectId("5142b8fc174328d087ac49c4"),
	"username" : "Shreddaz13",
	"imgPath" : ``ShreddazImage.jpeg''
},
"timeCreated" : ISODate("2013-03-15T06:00:42.313Z"),
"shredType" : "normal",
"shredComments" : [
	{
		"timeCreated" : ISODate("2013-03-15T06:00:42.313Z"),
		"text" : "Lorem ipsum lol cat mode19",
		"commenterId" : ObjectId("5142b8fc174328d087ac49ea"),
		"commenterName" : "Shreddaz51"
	},
],
"shredRating" : {
	"numberOfRaters" : 946,
	"currentRating" : 8188
},
"videoPath" : "battle-23-12-4.mp4",
"videoThumbnail" : "battle-23-12-4.jpg",
"tags" : [
	"Sound test",
	"Pop"
]
\end{lstlisting}

Similarly there are collections for Battles and BattleRequests. Notice there are only 4 different collections in this MongoDb implementations. This can be compared with the SQL implementation from Architecture 1.0 that is implemented with 16 tables. The reason I have chosen to limit the amount of collections as much as possible is to avoid the tedious join operations that would normally be needed in SQL. Joins are very slow, and also, they are not natively supported in MongoDb. One has to manually implement joins by performing multiple subsequent read operations across documents. My solution however emphasizes the use of duplicating data so that documents fit the domain in the way they are visualized in the App. Look for example at the Shred document in the example above. The owner consists of his Id, username and image path. Also, the comments contain the comment-owner's Id and username. This is exactly enough data that is necessary in the App, in order to visualize the Shred. In a normalized SQL (i.e Architecture 1.0) implementation the owner would just be represented by a foreign key, and during a Shred-fetch a join operation would have to be done for the Shred-owner, all the comment owners, every tag, and every rating. One misfortune with this design, however, is if any of the duplicated values were to change in the original document. For example if the Shredder with name Shreddaz13 was to change his profile image. In this case this update would have to be propagated to every place in the database where that particular image is referenced. However, I have acknowledged this fact simply because profile images aren't something that is likely to change very often. Another misfortune is that the database is somewhat App-aware. Imagine the API was to be used by other clients, maybe third party clients that would have other requirements to the amount of data that is populated with a particular fetch operation. One could argue that this customized duplication of data is somewhat enclosed for future needs. However, I have acknowledged that this data modeling decision is still very flexible, considering every domain resource always include their uid, making it possible to force join operations if more data needs to be  populated in a given query. 

\subsection{Summary of The Back-end}
The back-end is built as a Rest API that exposes a set of public operations. These operations are completely self-contained in that they contain all the information that is necessary to perform the operation without relying on any previous execution. Hence the back-end is completely stateless. 

Authentication is implemented with the Http basic authentication protocol. In order to no rely on a session implementation on the server, every Rest operation contains authentication details. This does require some amount of extra processing on the server during each request. However, every User's authentication details are stored in a Redis database, making lookups highly efficient. 

MongoDb was chosen to persist the domain objects, because MongoDb stores data in a JSON-like format, which is a very nicely fits the domain's data structure. The database is highly flexible, making it easy to store objects exactly how they would look like in the App. This is done by favoring duplication of data over structured relations that requires join operations. 
 
 \section{Summary}
 In this chapter we have looked at Architecture 2.0. This architecture is very much different from that of Architecture 1.0. Here, we have completely abandoned the state-full thick server by letting the application resolve around a large-scale JavaScript application that completely runs in the client. The server's job is to serve this application to the client's browser during the initial Shredhub request, a process we called the bootstrap process. 
 
 The front-end application has a decoupled structure where the code is organized into coherent modules. Domain logic is implemented in Models and Collections, while state and view-logic is implemented in Views. Alto, there is a central Router that hijacks Url requests to avoid Urls being sent to the server. 
 
The back-end is built around a Rest API that exposes self-contained operations to client users. The API uses JSON as the data format, which naturally fits into the overall programming environment, that is purely JavaScript based. Authentication does not rely on sessions on the server, because every Rest request contains authentication data. This requires fast authentication on the server, something that is solved by using Redis as a User/authentication database. The domain model is persisted with MongoDB where I have favored a nested and somewhat duplicated data modeling scheme, in favor for complex relations that requires join operations. The result is that the data in the database is highly optimized for the application's needs, but a potential drawback is that the data is somewhat rigid.


