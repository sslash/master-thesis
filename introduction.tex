\chapter{The Thesis at a Glance}     % 3-5 sider
\section{Motivation}
% Web 2.0
Web 2.0 is a popular term for the second generation World Wide Web. A new paradigm has emerged with the Internet's changing usage pattern that is increasingly becoming more social\cite{oreilly2007web}. In typical Web 2.0 sites, the users have their own profile account, they connect, collaborate and share information. What is special with these applications is that each user has a personalized view of the Web page, based on their account information and connections to other users. Many modern Web applications incorporate such social networking features.
                
% Data + UI
A characteristic property with Web 2.0 applications is that the users provide and consume the majority of the content. This often leads to large quantities of stored data. In addition, Web 2.0 applications often offer highly rich and interactive user-interfaces \cite[p.~158]{web20book}. The Web pages contain graphical widgets that display animated behavior, and clickable components that generate interactive responses. For this particular reason, such interactive Web sites are often referred to as Web applications, or in short "Web apps" rather then Web pages\cite{web-apps}.
                
% Scalable + efficient
A typical Web 2.0 application brings challenging requirements to its software architecture. Common usage behavior normally requires many and frequent data retrievals and updates, and the content should always be up-to-date. Considering the fact that the amount of persisted data is often very large, and the amount of simultaneous users is often very high, it is obvious that the back-end system must be both scalable and efficient. Also, the complex user interfaces require efficient graphical user interface code. This code has to be flexible and maintainable, in order to facilitate new user requirements, something that occurs very frequently for popular Web 2.0 sites\cite{userreq}. % F\aa en bedre reference!

% Browsers
It is not without reason that the quality of the user interfaces of modern Web applications has increased dramatically the last years \cite{JsWebApps}. Rich user-experiences primarily relies on efficient Web browsers that can execute client-side dynamic behavior. Earlier, demanding client-side behavior had to be implemented by technologies such as Flash\cite{flash} and Java applets \cite[p.~4]{spa}. These were highly efficient technologies that could run inside certain browsers. Older JavaScript engines, however, were not that efficient, so the purpose of the JavaScript was mostly limited to input validation and simple graphical behavior. However, modern JavaScript engines have become so powerful, that the browsers are now able to execute complex JavaScript code highly efficiently. This has facilitated the design of rich and interactive user-experiences that runs in any modern browser.

% Java Script web apps
The traditional software architectures for Web applications has in the last decade followed a thin-client approach. These architectures are heavily server-oriented in which most of the source code is executed in an application that runs on a Web server (the back-end). Also the information content is often stored in a relational database. For every URL request, the back-end is responsible for creating and delivering a dynamically generated HTML page to the client. The HTML code delivered to the client often contains a set of independent and unstructured JavaScript functions that generate the necessary interactive behavior. However, the rise of Web 2.0 has brought some interesting technologies and architectural concepts that makes it possible to build pure JavaScript applications that run primarily in the browser. Previously, this used to be rather pointless, because some five years ago, browsers were not able to host large-scale JavaScript applications. Also, such JavaScript Web applications are challenging to implement because the language itself lacks common features such as classes and namespaces. However, modern JavaScript frameworks provide syntactic sugaring enhancements that improves the programming experience, which makes it easier to build thick-client Web applications in pure JavaScript. In addition, modern Web applications tend to incorporate database solutions other than SQL, with the purposes of achieving better scalability and a simplified programming model. Such solutions are commonly referred to as NoSQL\cite{nosql}.  

This thesis investigates the pros and cons for developing a traditional Web 2.0 application by either using a traditional thin-client architecture backed by a SQL database, or an innovative thick-client architecture that uses NoSQL technologies. 
		
\section{Goals}
%Lately, there has been a dramatical change in the types of applications that are hosted on the Internet. These %applications offer highly interactive behavior and supports huge amounts of simultaneous users. At the same time, %software developers tend to rethink the way traditional Web applications are designed, and a lot of new architectural %proposals and Web technologies has emerged with this new Web paradigm. 

%% NEW GOAL: Find good solutions for both architectures and compare them
%% In order to solve the problem statement. The goal is to find pros and cons in both
%% In order to propose optimal hybrid solutions. 

The major goal for this thesis is to find optimal architectural principles in terms of scalability and performance, for building typical Web 2.0 applications. Performance in this case is scoped to end-user response times. The work that is done involves finding sustainable solutions for both the traditional thin-client and the thick-client approach. This way, a proper comparison will help identify significant pros and cons in each architecture. The results are used to give guidelines for good architectural decisions, and propositions for hybrid solutions and future work.

In the study of these two architectural approaches, there has also been a focus on code quality, considering this is important in order to facilitate future growth in any modern Web application. The purpose of this is to find sustainable methods to structure the code in both the thin-client and thick-client approach. This way, the codebases can also be compared in order to give further reasons to choose any of the two architectures. 
        
It is important to have in mind that a server back-end can only be scalable up to a certain point, in which case the only solution to achieve further scalability is to upgrade the server hardware, or add more physical servers. Considering that this is both resource demanding and time consuming, I limit my investigation to apply mostly to single server deployments. Additionally, as for the thick-client JavaScript architecture, the goal for it is to work ideally in modern Web browsers, as older browsers lack ability to execute large-scale JavaScript applications. 

Also, even though security is a big issue when it comes to designing Web applications, I have decided not to focus on this, simply because it would be too time consuming and laborious. The only security issue I bring to attention is authentication, because it has a very high impact on the overall architecture of the Web application. The goal is not to find the best authentication protocol for any Web app architecture, but rather to find reliable solutions that fit the architectures we discuss. 


\section{Problem Statement}
In this section, we look at the main questions we want to solve in the thesis. The term ``Web app'' is being used to refer to typical modern Web 2.0 applications that contain rich and responsive user interfaces, incorporates social networking, and manipulates large amounts of persisted data. The main question we ask concerns the benefits, if any, for having a \textbf{thick-client} Web app architecture instead of a traditional \textbf{thin-client} architecture. We separate this problem statement into three more specific questions: 

\begin{enumerate}
\item{} In traditional Web apps, HTML pages are dynamically generated on the server, which is done in every URL request. Can Web apps achieve better performance and scalability results by dynamically creating pages on the client, and by using the server only as an interface to the database? 
\item{} In traditional Web apps, state is kept on the server. Can Web apps perform and scale better by moving state completely to the client? Also, if state is moved to the client, can Web apps benefit from moving business logic operations to the client as well? Benefits are evaluated in terms of performance and also programmer satisfactory aspects such as code flexibility and simplicity. 
\item{} In traditional Web apps, the data is persisted in a relational database management system by using SQL as the query language. However, new types of database systems (commonly called NoSQL) offer a different, schema-less persistency solution that is often specialized to fit a specific type of application. Is there any such database system that particularly  suits the thick-client architecture, and can they make it perform better then a typical SQL database implementation? Are there any programmer satisfactory advantages of using such a NoSQL database in Web apps? 
\end{enumerate}


\section{Approach}
Considering the main goals for this thesis is to compare two different approaches to Web application architecture, a good way to get sustainable and reliable results is to design and implement an actual application, by using both of these approaches. I have defined two manifests that outlines the major principles in respectively a traditional thin-client architecture that uses SQL, and an innovative thick-client architecture that uses NoSQL. These manifests are called \textit{Reference-model 1.0} and \textit{Reference-model 2.0}. In addition, I have come up with an idea for a typical Web 2.0 application that conforms to the user requirements stated earlier. This  application is built twice from the start with two completely different architectures. One implements the principles from \textit{Reference-model 1.0} while the other implements \textit{Reference-model 2.0}. 

To get good and valuable results, extensive system-testing has been done on both prototypes. A set of concrete test cases have been proposed and executed on both architectures. The test cases are designed to test the performance and scalability behavior of the applications, in addition to a minor test that studies the two source codebases. To be able to do this, a lot of dummy data has been generated and used to populate the databases. In addition, the testing was done by running simulations that generates a high number of simultaneous user requests. 

\section{Proposed Solution}
For this thesis I have proposed a Web application called \textit{Shredhub}, which is a social networking site primarily designed for musicians. The application features common behavior found in traditional Web 2.0 applications.

Shredhub has been built twice, using a traditional approach, named \textit{Architecture 1.0}, and an innovative approach, named \textit{Architecture 2.0}.
\paragraph{Architecture 1.0} conforms to the following principles:
\begin{itemize}
\item{} HTML is dynamically generated on the server
\item{} State handling and business logic is implemented on the server
\item{} Stores data in a SQL database
\item{} A set of autonomous JavaScript functions are used to generate quick and responsive behavior
\end{itemize}

\paragraph{Architecture 2.0} conforms to the following principles:
\begin{itemize}
\item{} HTML is dynamically generated on the client
\item{} State handling and business logic is implemented on the client
\item{} Uses NoSQL technologies to persist data
\item{} The application is kept in the browser and implemented purely in JavaScript
\end{itemize}

\section{Evaluation}
The evaluation is based on implementation observations and the tests that were performed on Architecture 1.0, and Architecture 2.0. The tests were designed to investigate efficiency, scalability and to some extent, source code quality. 
\paragraph{Efficiency} has been evaluated in terms of the response time when an action is performed on Shredhub. The action might be clicking a link in a tab that leads to a new page, uploading a video, rating a video, etc. The evaluation is based upon how fast the architecture is able to generate the result. In addition, to investigate database efficiency, evaluation is in this case based on how fast the architectures execute the most popular database queries used in Shredhub. Also, an evaluation of the back-end efficiency is based on how much time is spent on the server for each test case. 

\paragraph{Scalability} is evaluated in terms of how well the architectures deal with an increasing number of simultaneous requests. This has been done by creating multiple threads that simultaneously execute common user actions on Shredhub. The evaluation is based on, for each number of simultaneous requests in the set of \textit{U=\{1,10,100,200,400,600,800,1000\}} where U is simultaneous users, how fast the results are being delivered, and how many users the Web app can at most handle before it no longer returns valid answers. 

\paragraph{Source code quality} is only a minor evaluation point in this thesis, much due to the limited amount of time there was to test this in this thesis. However, considering that this is also very relevant in terms of comparing the two software architectures, some evaluation has been done. The two codebases are compared in terms of the amount of lines of source code, the number of different programming languages used, and lastly, how much code had to be modified and added when a new user requirement was introduced and was to be implemented in the already finished codebase. A final test case was designed to involve both the implementation of a graphical user interface component, a business logic operation, and a new database operation. In addition, an observation of general programmer satisfactory aspects was noted during development. 																											
\section{Work Done}
The initial work done for this thesis was to identify common characteristics in modern Web 2.0 applications. This lead to the design concept for a Web application that could incorporate these characteristics in the application's user requirements. At the same time, a lot of work has been done in studying architectural trends in modern Web applications. A lot of time was spent looking at open-source code repositories, read technology blogs, books, watch Web-seminars and presentations, and reading online discussions on modern Web architecture. Coincidentally not a lot of research has been done on thick-client JavaScript based Web applications, therefore much of the knowledge is based on the sources just described. It was important to get a comprehensive overview of the common trends in Web architecture in order to decide on the most industry-relevant solutions for the prototypes that was developed in this project.

Further, the work involved the design and implementation of the two prototypes. The implementation process had a strong focus on keeping the applications look exactly the same from a user's perspective, while at the same time focusing on developing the architectures in two completely different ways.

The last part involved deciding how the two architectures was to be tested and compared. This work involved defining a set of concrete test cases aimed to test the performance and scalability behavior for the applications. Finally the two architectures were deployed on a test machine, and the tests were executed on them. In addition, the two codebases where revisited in the implementation of an additional user feature, so that the code could be compared in terms of flexibility and simplicity. 

\section{Results}
The results show clear advantages for Architecture 2.0. Modern Web 2.0 applications can successfully benefit from generating dynamic HTML on the client. The reason is that generating HTML on the server can be a tedious job, especially when the amount of simultaneous users is high. This behavior was fully possible to implement with client-side JavaScript. Also, state and business logic was successfully moved to the client by building a full-scale JavaScript application that is sent to the browser on initial Web page requests. The benefits are that a lot of load is taken off the server, leading to higher scalability and performance results. However, it does require a modern browser, and also the initial page request could be significantly slow.  Also, another disadvantage was that some business logic had to be duplicated on both the client and the server, and also that the Web app itself is not properly picked up by Web crawlers. The programming benefits were great, because code that manipulates the user-interface lies closer to, and cooperates better with the application's logic code, because they exist under the same programming language abstraction (module).  

As for the database solutions, there are very many NoSQL technologies to choose from. However, one solution was found for Architecture 2.0, that nicely fits the domain for Shredhub. The results were that some queries were very efficient in cases where the domain could fit under the same database entity, but slow in cases where multiple entities had to be joined together. In those cases, SQL were much more efficient. On the other hand, the NoSQL solution was very programmer satisfying, because no translation between objects in the back-end and the database had to be done, because they share the same programming language. 
