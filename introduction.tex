\chapter{The Thesis at a Glance}     % 3-5 sider

Web 2.0 is a popular term for the second generation World Wide Web. A new paradigm has emerged with the Internet's changing usage pattern that is increasingly becoming more social \cite{web20}. In typical Web 2.0 sites, the users and their activities is the main information content, and users are actively involved by connecting and interacting with each other. Examples of such web sites are Internet blogs, chat services, wiki's, video sharing sites, mashups and other social networking services. A characteristic property with such an application is that there are a lot of simultaneous users all in which communicates with each other asynchronously on the Internet. Users registers themselves on the social networking site by entering information that fits their personal profile. After registering, the users can normally search for other users and send requests to connect. These connections makes up a graph of interconnected users, hence the term "social network" (REF) . Based on the information the users stores about themselves they can get various personal recommendations like what movies a given user probably likes, suggested friend-connections, suitable dining places etc. 
                
A characteristic property with Web 2.0 applications is that the information-content on the web pages are primarily generated by the users. Having the users generate and share content with each other often leads to huge amounts of data stored in the application's databases. This differs from other web sites where the creators (or owners) themselves generates the content on the pages, and the amount of data is seldom of such large quantities. In addition to this, another characteristic property with Web 2.0 applications is that the sites often offers highly rich and interactive user-interfaces. The web pages contains graphical widgets that displays animated behavior, and clickable components that generates interactive responses. Of this particular reason, such interactive web sites are often referred to as web applications, or in short "web-apps" rather then web pages (referanse!). 
                
A typical Web 2.0 application is a system that brings a challenging requirement for it's software                 architecture. Common usage behavior normally requires many and frequent data retrievals and updates. Considering the fact that the amount of data that is stored in a typical web-app is often very large, it is obvious that the backend architectures needs to be both scalable and efficient. The high amount of dynamic and interactive user interfaces requires much, and often complex graphical user interface code. This code has to be flexible and maintainable, in order to facilitate new user requirements, something that happens to occur especially frequently for popular Web 2.0 sites. (REFERENASE) Also, the user interface code required for interactive web-apps has to be at most efficient, in order to achieve proper responsive behavior. In addition, the amount of users that simultaneously accesses the web-apps are often high. This puts a high demand for scalability on the server(s) that hosts the given application. To meet with these requirements, application developers has to pursue a software architecture that both performs fast and is scalable. 

It is not without reason that the quality of the user interfaces of modern web applications has increased dramatically the last years. Rich user-experiences primarily relies on efficient web browsers, because it is the browsers that executes most of the dynamic behavior of a web-app. Earlier, demanding front-end behavior had to be implemented by technologies like Flash and Java applets, mainly because these technologies executes in efficient run-time environments. Older JavaScript engines were not that efficient, so the purposes of JavaScript were mostly limited to simple graphical behavior. However, modern JavaScript engines have become so powerful, that the browsers are now able to execute complex and intensive JavaScript code. This has facilitated the design of rich and interactive user-experiences that can be seen in modern web-apps.

The traditional software architectures for web applications has in the last decade followed a thin-client/thick-server approach. These architectures consists of a client tier, a logic tier and a data tier, where most of the application's source code is executed on the server (backend), and the data tier is often implemented with a relational database. The logic tier is responsible for creating and delivering a dynamically generated HTML page to the client, upon a URL request. The HTML code delivered to the client contains just about enough JavaScript functionality to generate the necessary interactive behavior. However, the rise of Web 2.0 has brought some interesting technologies that has made it possible to implement full applications primarily in the client tier (i.e the HTML, and JavaScript that executes in the browser). This has for long been pointless, because some five years ago, browsers weren't even able to host large-scale JavaScript applications. Also, large-scale JavaScript web applications are difficult to implement and maintain, because the language itself lacks idioms and semantics that suits substantial codebases. However, modern JavaScript frameworks provides syntactic sugaring enhancements that improves the programming experience, which makes it easier to build front end applications in pure JavaScript. All together, these modern technologies might simplify the development of interactive and scalable web applications. 

Lately, one has seen a large amount of innovating and pioneering changes in the way developers tend to design modern web architectures. The classical three-tier architecture with a fat server performing all of the application's business logic and old SQL database is no longer necessarily the best solution for every web application. Even though, there are still many advantages with the traditional approach, considering the architecture has been a de-facto standard for many years. The work that has been done in this thesis is an analysis of the pros and cons for developing a traditional Web 2.0 application by using either a traditional web application architecture, or a modern and experimental web application architecture that is empowered by modern web- and database technologies.


\section{The Hypothesis / Problem Statement}
In this section, we look at the main questions we want to solve in the thesis. We use the term ``Web app'' to refer to typical modern Web applications that contains rich and responsive user interfaces, incorporates social networking, and manipulates large amounts of persisted data. The main question we ask concerns the benefits, if any, for having a \textbf{thick client}/thin server Web app architecture instead of a \textbf{thin client}/thick server architecture. We separate this problem statement into three more specific questions: 

\begin{enumerate}
\item{} In traditional Web apps, dynamic HTML pages are generated on the server, which is done in every Url request. Can Web apps achieve better performance and scalability results by rendering pages on the client, by using the server only as an interface to the database? 
\item{} In traditional Web apps, state is kept on the server. Can Web apps perform and scale better by moving state completely to the client? Also, if state is moved to the client, can the Web app benefit from moving the  business logic operations to the client as well? Benefits are evaluated in terms of programmer satisfactory aspects like code flexibility and maintainability, and also performance. 
\item{} In traditional Web apps, the data is persisted in a relational database management system by using SQL as the query language. However, new types of database systems (commonly called noSql) offers a different, schema-less persistency solution that is often specialized to fit a specific type of application's data modeling need. Is there any such database system that can make Web apps perform better then a typical SQL database implementation? Are there any other advantages of using such a noSql database in Web apps, like programmer satisfaction? 
\end{enumerate}

		
\section{Goals}
%Lately, there has been a dramatical change in the types of applications that are hosted on the Internet. These %applications offer highly interactive behavior and supports huge amounts of simultaneous users. At the same time, %software developers tend to rethink the way traditional web applications are designed, and a lot of new architectural %proposals and web technologies has emerged with this new web paradigm. 

%% NEW GOAL: Find good solutions for both architectures and compare them
%% In order to solve the problem statement. The goal is to find pros and cons in both
%% In order to propose optimal hybrid solutions. 

The goal for this thesis is to find a superior software architecture for the type of traditional Web 2.0 application that was defined in the beginning of this chapter. Modern Web applications are commonly built using traditional thin client architectures, but thick client solutions are getting increasingly more popular. Therefore, we will investigate modern and   innovative Web architectures in order to find the pros and cons in choosing a traditional Web architecture, versus a modern Web architecture. 
	
	Obviously there will never be one architectural design that is the best fitting design for every web 2.0 application. After all, Web 2.0 is just a common name for web applications that are meant for social user interactions, and these applications varies in many ways. Therefore, the goal for this thesis is not to find a solution that is best suited for one particular application. Instead, the objective is to engage the common principles of such applications, like rich user interfaces and domain data made up of interconnected users, blog posts, comments and tags. These principles will be applied in the development of a Web 2.0 application that is to be deployed on a test server. Hence the goal is to find architectural \textbf{design principles} that are well suited to solve the most common properties of a web 2.0 application.  
	
The experiments that has been performed on the prototype serves to investigate how modern web technologies can be applied to achieve a scalable and responsive web application that delivers dynamic and interactive content to a big amount of simultaneous users. The goals are to find the bottlenecks and benefits in a classical thick-server architecture, using a traditional SQL database. At the same time, I have studied the benefits and pitfalls from applying a thick-client JavaScript based web architecture, with a simple backend that runs a noSQL database.  

In a classic web 2.0 application it is at most important to have a code base that makes it easy to add new features. Therefore, part of the goal of this project is to design a software architecture that is flexible and maintainable, so that one can easily add new behavior and modify existing features. It is a known fact that JavaScript code tend to be tightly coupled with the HTML and CSS styling it dwells in, and therefore, it is an important design criteria that the thick client architecture is both well-structured and code-intuitive. I will strive to apply appropriate design patterns both on the backend and especially on the client, to enforce a flexible and maintainable code base.  
        
It is important to have in mind that a server backend can only be scalable up to a certain point, in which case the only solution to achieve further scalability is to upgrade the server hardware, or add more physical servers. Considering that this is both resource demanding and time consuming, I will limit my conclusions to apply only for single server deployments. As for the client users, the goal for the prototype is to work ideally for modern web browsers, as older browsers lack performance ability to execute large-scale JavaScript applications. Therefore the prototype will only be tested on modern web browsers.

Even though security is also a big issue when it comes to designing Web applications, I have decided not to focus on it, simply because it would be too time consuming and laborious. The only security issue I bring to focus is authentication, because it has a very high impact on the overall architecture of Web applications. The goal is not to find the best authentication protocol for any Web-app architecture, but rather to find simple solutions that fits the architectures we will discuss. 


\section{Approach}
Considering the main goals for this thesis is to compare two different approaches to web application architecture, a good way to get good and reliable results is to design and implement a software application, and use this as a base for experiments. The goal is to identify the pros and cons with a traditional web architecture, versus a modern and experimental architecture. For this thesis I have come up with an idea for a traditional web 2.0 application that conforms to the user requirements stated above. The application is a social networking site where users connect to each other, and creates and posts blogging content. Users will perform common blog related actions like commenting, tagging and give ratings. The application is built twice from the start with two completely different architectures. The first is a traditional thick-server/thin-client model that uses a SQL database to store its data. The server encapsulates all the business logic, which is  implemented in a commonly used programming language. The other is a thick-client JavaScript based web application that just uses a backend server as means to store persistent data. This means that most of the business logic is located in the client tier. It uses a noSQL database to store the data.

To get good and valuable results, extensive system-testing has been done on both prototypes. There has been proposed a set of concrete test cases that has been executed once for each of the two architectures. The test cases are designed to test the performance and scalability behavior of the applications. To be able to do this, a lot of dummy data has been generated and used to populate the databases. In addition, the testing was done by running test simulations that generates a high number of simultaneous requests. For most of the test cases the number of requests was increased until the server could no longer scale to deliver reasonable responses. 

\section{Proposed solution}
For this thesis I have come up with a web application that I call \textit{Shredhub}. This is an approach to a classical web 2.0 application, primarily designed for musicians. The web-app allows users to register themselves as musicians, deploy videos of them playing and tag the videos with various categories. Other users can watch the videos, rate them and leave a comment. Users connect to each other in a typical social-networking manner, and they receive suggestions for other users they might be interested in connecting to. The web app contains some graphical widgets that requires dynamic JavaScript behavior, and the amount of data that is persisted grows exponentially with the amount of interactive users. 

For the purposes of this thesis, the application is built twice with two completely different software architectures, where the first conforms to a traditional web architecture, and the latter incorporates principles of modern JavaScript-based web architectures. The two approaches are respectively named \textit{Architecture 1.0} and \textit{Architecture 2.0}.

\paragraph{Architecture 1.0} is a built with en emphasis on a thick server implementation that contains all the business logic needed for the application to work as intended. The server is built in Java, which is a commonly used programming language for backend web applications. The server works by responding to URLs that is initiated by the users. For each URL request the server would build and render an HTML page that contains the necessary JavaScript functions to deliver dynamic behavior for the given page. The HTML page is sent back to the user's browser, which does not have to perform much JavaScript processing, since the HTML page is already pre-rendered and ready to be painted on the screen. The whole backend service is built around the MVC design pattern, and incorporates other architectural design patterns for structuring the codebase.

As for the persistency layer, the solution uses a PostgreSQL database, which is a popular open-source implementation of a relational database management system. The backend server that is written in Java contains code to communicate with the database.  The front end tier is implemented in JSP which is a templating language that is transferred into HTML during each user request. The HTML code that is generated contains self-contained and independent JavaScript functions that is mixed inside the HTML code.
Also, client state is being kept on the server, meaning that the server has state information for every currently logged-in user, stored in memory. Hence the server depends on a session identifier in each URL request in order to identify the user's session. This identifier is stored in a \textit{cookie}.

\paragraph{Architecture 2.0} is built with an emphasis on modern web technologies and business logic running mostly in the client tier. The backend tier is composed of a simple web interface that receives initial requests for the web site, and responds with a big assembly of JavaScript files that makes up the web application. After the initial request, the backend server answers to data requests that targets the persisted data objects stored in the database. These objects are returned from the server in a fine-grained transfer format. This client-server interaction is very different from that in \textit{Architecture 1.0} where the server always reacts by rendering and returning complete HTML pages. 
The client tier is structured around a variation of the MVC pattern, and implemented with a JavaScript framework called BackboneJs. This framework helps structuring large-scale JavaScript applications by integrating modules, utility functions and event handling in the JavaScript tier. 

The JavaScript tier is responsible for constantly rendering HTML pages based on the user's actions. From the programmers perspective, these HTML files are completely separated from the JavaScript files, and the JavaScript files are separated in loosely coupled modules. By using a technique called asynchronous module loading, it is possible for every JavaScript module to define which HTML pages and other JavaScript modules it depends on, and further load these dependencies asynchronously each time a given JavaScript module is executed. This enhances the interactive experience from a user's perspective, because the browser never blocks while loading in new modules. 

Also, the client state is stored in the client's browser, so that no state information is kept on the server. This is done by using HTML5 local storage, which is a simple key-value container that is persisted in the browser. This way, user events are handled primarily by the JavaScript tier, and the JavaScript tier will only contact the server when it needs to access persistent data. The persistency data itself is stored in a noSQL database called MongoDB, which is an open source, document-oriented database technology. It's data is stored as JavaScript objects, which makes a consistent interaction model across the whole software stack in the web application. 



\section{Evaluation}
The evaluation is purely based on tests that has been performed on the Architecture 1.0, and Architecture 2.0. The tests were designed to track down efficiency, scalability and to some extend source code maintainability. A testing framework has been used to create fictive test stubs that imitates browser requests. This framework has the ability to create hundreds of thousands of simultaneous running threads, such that the architectures can properly be evaluated in terms of how well they respond to these tests. In addition, a set of tools to measure the client-server roundtrip time, and to track the browser's rendering process upon page loads, has been used to test and the efficiency of the two architectures. 

\paragraph{Efficiency} has been evaluated in terms of the response time (in milliseconds) when an action is performed in the web app. The action might be clicking a link in a tab that leads to a new page, uploading a video, logging into the web app etc. Considering that the response time is not just a single result when it comes to performing an action, because the process of rendering a web page is a matter of multiple request-response cycles, the evaluation is based on multiple factors. This includes how fast the browser displays an initial result, or in other words, how long the user has to wait before he sees anything at all, how much time it takes before the user can start interacting with the page, and how much time it takes before the whole action is complete. 

\paragraph{Scalability} is evaluated in terms of how well the web app deals with an increasing number of simultaneous requests. This has been done by creating multiple threads that simultaneously executes the same action on the web app. The evaluation is then based on, for each number of simultaneous request in the set of \textit{Sq=\{1,10,100,500,1000,10000,100000,500000\}} where Su is simultaneous requests, how fast is results being delivered, and how many requests can the app at most handle before it no longer returns valid answers. 

\paragraph{Source code maintainability} is only a minor evaluation point in this thesis (much due to the limited amount of time there is to test this in this thesis). However, considering that this is also very relevant in terms of comparing the two software architectures, some evaluation has been done. The two codebases are compared in terms of the amount of lines of source code, the number of different programming languages used, and lastly, how much code had to be modified and added when a new user requirement was introduced and was to be implemented in the already finished codebase. The latter test case was designed to involve both the implementation of a graphical user interface component, a business logic operation, and a new database operation. 

All tests has been done when the two web apps were deployed on a web server stationed in Stockholm, Sweden, in order to get reasonable transmission delays. Also, in order to test the performance results on a relevant set of browsers, the efficiency tests has been tested on both the newest version of Google Chrome, Mozilla firefox and Internet Explorer.  


\section {Problem statement}
Current Internet devices like desktop computers, smart phones and tablet devices has a high capability for performing resource demanding processing jobs and intensive network transmissions. This makes it possible to build performance demanding front-end applications that can run on these devices. However, the traditional three-layered web architecture is often built with an emphasis on limiting the amount of processing that is to be executed on the client's device. This is done by leveraging the high processing power of the web servers, such that most of the demanding computing tasks are performed on the servers, and the finished HTML-results are prepared and sent to the front-end clients. It is interesting to study how web applications can benefit from moving much of the business logic into the client's device instead of letting the server perform most of this computation. The fact that a classical Web 2.0 application requires lots of simultaneous users with high amounts of data       requests, makes it interesting to see if such an architecture might result in less load on the server. However, having lots of business logic on the client means lots of JavaScript code, since JavaScript is the one and only cross-platform language supported by all web browser(REF?). Now, it so happens that the JavaScript programming language has ever since its dawn of time been used just as a supplement to HTML pages, just to provide the necessary dynamic behavior. The language itself is not intended to develop large-scale software applications, and it is therefore challenging to build a big and maintainable JavaScript code base. To cope with this, web developers has spent lots of time lately to build open-source JavaScript frameworks that serves to ease the challenge of creating large-scale  JavaScript web apps. This makes it interesting to study the benefits of developing a modern Web 2.0 application with a pure JavaScript implementation, rather then a backend-oriented traditional software architecture.

% These frameworks are often centered around the Model-View-Controller\cite{mvc} design pattern. %This is logical structure of the code base, that mostly has been used to structure the code on the %server, for traditional web apps. In the case of front-end based web apps however, the MVC pattern %is mainly deployed on the client.
        
        %an MVC-style architecture, except that they normally does not
        %%completely conform to the design pattern. The reason is that
        %these JavaScript frameworks often has their own individual
        %implementations of the controller module. Therefore, it is
        %normal to name the pattern simply MV*. One example is the
        %MVP pattern, where the P stands for presentation. The
        %presentation layer implements the mediator design pattern
        %\cite{facade} which communicates with both the view, and the model. In this
        %scenario, the communication is event driven, in which the
        %presentation layer would bind to the events generated by the
        %model, and publish the result of these events to the view
        %layer. 

Another interesting scenario with Web 2.0 apps is the massive amount of data that is being persisted in these kinds of applications. It is the users that creates the application's content through blogs, wikies and social interactions, and the data magnitude expands with the increase of users and their interconnections. With the demand to persist such large data quantities, and to perform efficient operations on them, one has seen lots of new and innovate database technologies. These new types of database systems all have in common that they distinguishes themselves from the traditional relational database. The aims for these generally focuses on the ability scale over multiple machines (horizontal scaling), and perform highly efficient on large persistent data quantities. This paradigm has been named noSQL, and examples include document-oriented databases, column-oriented databases, and key-value databases. A common factor with these noSQL databases is that they have showed to perform great in cloud environments because of their horizontal scaling abilities (unlike traditional SQL databases). Naturally this fits great with the requirement of a traditional web 2.0 application, because it requires high performance in data lookups even when the size of the data quantity is extremely large. Still however, many developers favors thetraditional SQL database implementations because of its elegant schema design, efficiency, and also the fact that most developers has profound knowledge and experience in the field of relational database management. The question of wether a noSQL database has any benefits compared to using a traditional database in a thick vs thin client architecture is an interesting topic. Besides the scalability question, which seems fairly self-proven, there are other not so revealing problem statements, like what sort of queries are best suited for the various database technologies.
        %, which architecture
        %performs best when deployed on one single server, and on multiple servers. And
        %finally, how easy is it to implement the databases
        %in a given web application, in terms of programmer
        %friendliness and maintainability.   

The problem statement in this thesis is centered around two main topics:

\begin {enumerate}
\item Can a thick client web architecture help make an interactive web 2.0 applications perform better? This must be evaluated in terms of performance, in which the response time for end-users is the main evaluation criteria. This must be tested both when the number of simultaneous requests are small, and when the number increases. This must be done in order to simulate a real-world scenario of a modern web-app. Also, scalability must be evaluated in terms of the ability for the backend server to deliver reasonable responses when the number of simultaneous requests increases.  The problem statement is limited to a single server environment, simply because proper testing in a multi-server environment is too time-consuming for this thesis. 
          An additional problem statement is the question of wether there are any programming benefits from building a large-scale JavaScript application, compared to developing a traditional thick server architecture built in a traditional programming language like Java. Just like in the traditional approach, the large-scale JavaScript application is built around the MVC design pattern, in order to achieve a good structuring of the codebase. This makes it  feasible to compare the quality of the two source codebases. The programming benefits must be evaluated in terms of intelligible, and structure. However, the task of evaluating flexibility and long-term maintainability is very demanding and time-consuming. Therefore, the problem statement is limited to simple comparisons and evaluation of the structure and intelligibility of the two codebases.  
 
\item	Are there any noSQL databases that are particularly more suitable for a typical web 2.0 application than ordinary SQL databases? The problem statement is especially relevant for web 2.0 applications, because of the type and amount of information that is stored in such applications are extraordinary compared to other types of web applications. The persistence technologies must be evaluated in terms of efficiency and scalability. Is it the case that it's always better to use one of the other, or are there any special types of operations or queries that are better solved by any of the particular database technologies. Like with the problem statement above, programming satisfaction must also be a design goal. In this case, simple evaluation criteria like ease of development and intelligibility will be considered, in order to maintain an appropriate scope for the thesis work. Now, it is so that there are a lot of various noSQL, and SQL databases, so the task of finding the best solution for all of these is simply to overwhelming for this thesis. Therefore, the problem statement is limited to finding one representative noSQL database, one and SQL database, and the evaluation will be based on a performance measurement on these. The database technologies chosen must be widely used in the web application industry, which is important in order to get valuable results.   
\end{enumerate}
	
% A final goal for the prototype is that it can be executed on smart phones and tablet devices in addition % to laptop/desktop computers. This is important because modern users of web applications % often accesses such applications through their personal smart phone or tablet device.
%The final goal is to achieve a cross platform solution for the
  %      application that makes it easy to build new client
    %    applications on top of the current backend solution. This is a
     %   fundamental requirement for any web 2.0 application,
      %  considering current Internet users uses a various range of
       % devices, including mobile phones, tablets and normal desktop
        %computers. For example, it should be possible to implement a
       % native iPhone app, or windows 8 tablet app or a third party
       % web page that, that will use the service offered by the
        %application's backend implementation. A design criteria is to
        %achieve reusable components, so that much code can be reused
        %without having to build many customized solutions.

\section{Work done}
The initial work done for this thesis was to identify common characteristics in web 2.0 applications. This lead to the design of a web application that could incorporate these characteristics in the application's user requirements. The application was first designed from a user's perspective with an emphasis on rich user interfaces, with dynamic and interactive behavior. At the same time, a lot of work has been done in studying architectural trends in modern web applications. The author of this thesis has spent much time looking at open-source code repositories, read technology blogs, books, watch web-seminars and presentations, and read online discussions on web architecture. It so happens that not a lot of research has been done on modern web application design, so much of the knowledge is based on the sources just described. It was important to get a comprehensive overview of the common trends in web architecture in order to decide the most suitable solutions for the prototypes that was developed in this project.

Further, the work involved the design and implementation of the two prototypes. The implementation process had a strong focus on keeping the applications look exactly the same from a user's perspective, while at the same time focusing on developing the architecture in two completely different ways. A list of the code that has been implemented in given in the list below. Note that the list applies to both of the prototypes:
\begin{itemize}
\item{} Design and implement user interfaces with HTML, CSS and JavaScript
\item{} Implement business logic, including validation rules and business processes 
\item{} Implement database scripts to generate the databases
\item{} Implement code to communicate with the database
\item{} Implement backend functionality to communicate with client users through HTTP
\item{} Create scripts to generate dummy data
\item{} Deploy the prototypes on a self-hosted server
\item{} Test the implementation to verify that it works as expected
\end{itemize}

The last part involved deciding how the two architectures was to be tested and compared. This work involved defining a set of concrete test cases aimed to testing the performance and scalability behavior for the applications. The test cases are designed to identify efficiency properties, bottlenecks and capacity limits. Finally the tests were run on the test machine that was hosting the applications. The tests were performed both physically by an active user, issuing requests from the browser and registering the round-trip times, and the were performed by using testing tools that are are able to create multiple dummy requests. The testing tools where used to check the scalability behavior be increasing the number of simultaneous requests, until the server were no longer able to respond with reasonable results, or crashed. 

In addition, the two codebases where revisited and compared in terms of flexibility and comprehensibility. The work was a rather short evaluation including a structured table-comparison of the significant pros and cons. This was important to get a complete overall evaluation of the two software architectures.

%	During the work on this thesis I have read many articles and books on design patterns because It was important to get a good understanding of all the patterns that has gotten public 
%familiarity. To learn how to adopt them into my own coding style, I tried building various prototypes where I would apply the patterns I had read about. I wanted to get an understanding of how the 
%patterns could work and collaborate in a bigger software application, and especially one that had some complex software requirements. The solution was to build a classic web 2.0 application and 
%apply various design patterns, compare them and do testing based on some well-defined metrics. I made a report of the results I got after running the stated tests, and draw a conclusion based on 
%these. 

\section{Results}
The results shows that the modern architecture achieves better performance results both for responds time, and backend scalability. The reason is that since it avoids involving the server as much as possible, less data is sent between client and the server. Also, it achieves an interactive user experience by following an asynchronous page loading approach, giving the user the impression that the page instantly responds to requests. In addition, the noSQL implementation achieves very high quering speed, because it avoids doing tedious join operations between multiple tables. This results in higher scalability for Archtiecture 2.0. A benefit with Architecture 1.0 however, is that the solution is easy to implement for most developers, because the coding style is very familiar. The result is that many programmers will probably spend less time developing the first architecture then the latter. 
%	The domain layer of the three-tier web application is built around the domain model design pattern. It uses the Identity map pattern as an in-memory cache, and lazy loading techniques to 
%achieve scalability and efficient data requests. The reason I chose this architecture was that I found out that the Identity map pattern fits nicely into a web application that requires frequent lookups 
%into an in-memory data structure. It was easy to use the lazy-loading pattern with the identity map, which again made it easy and clear what data was in memory, and what was written to the 
%database. Having this advantage made it easy to scale the application to meet the scalability requirements of a classical web 2.0 application.  
%	To integrate privacy rules with the data structure, I use the proxy design pattern which makes it easy to have one abstraction of a user, but multiple implementations depending on the privacy 
%rules. To implement a flexible matching feature in the test-application, I use the decorator pattern so I can easily add and remove matching premisses for users. Finally, to make it easy to add and 
%modify existing business logic, I use the command design pattern that is built around a service layer. 

\section{Contributions}
%	Too early to say something about

\section{Criteria}






In chapter 1 : security is at most a secondary concern. Its only authentication. 
